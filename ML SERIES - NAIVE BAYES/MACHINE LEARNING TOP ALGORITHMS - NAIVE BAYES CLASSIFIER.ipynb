{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAYES CLASSIFIERS\n",
    "\n",
    "For any classifier $f:{X \\to Y}$, it's prediction error is:\n",
    "\n",
    "$P(f(x) \\ne Y) = \\mathbb{E}[ \\mathbb{1}(f(X) \\ne Y)] = \\mathbb{E}[\\mathbb{E}[ \\mathbb{1}(f(X) \\ne Y)|X]]$\n",
    "\n",
    "For each $x \\in X$,\n",
    "\n",
    "$$\\mathbb{E}[ \\mathbb{1}(f(X) \\ne Y)|X = x]  = \\sum\\limits_{y \\in Y}  P(Y = y|X = x) \\cdot \\mathbb{1}(f(x) \\ne y)$$\n",
    "\n",
    "The above quantity is minimized for this particular $x \\in X$ when,\n",
    "\n",
    "$$f(x) = \\underset{y \\in Y}{argmax} \\space P(Y = y|X = x) \\space \\star$$\n",
    "\n",
    "A classifier $f$ with property $ \\star$ for all $x \\in X$ is called the `Bayes Classifier`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the assumption $(X,Y) \\overset{iid}{\\sim} P$, the optimal classifier is:\n",
    "$$f^{\\star}(x) = \\underset{y \\in Y}{argmax} \\space P(Y = y|X = x)$$\n",
    "\n",
    "And from _Bayes Rule_ we equivalently have:\n",
    "\n",
    "$$f^{\\star}(x) = \\underset{y \\in Y}{argmax} \\space P(Y = y) \\space P(X = x|Y = y)$$\n",
    "\n",
    "Where\n",
    "- $P(Y =y)$ is called _the class prior_\n",
    "- $P(X = x|Y= y)$ is called _the class conditional distribution_ of $X$\n",
    "\n",
    "Assuming $X = \\mathbb{R}, Y = \\{ 0,1 \\}$, and the distribution of $P \\space \\text{of} \\space (X,Y)$ is as follows:\n",
    "- _Class prior_: $P(Y = y) = \\pi_y, y \\in \\{ 0,1 \\}$\n",
    "- _Class conditional density_ for class $y \\in \\{ 0,1 \\}: p_y (x) = N(x|\\mu_y,\\sigma^2_y)$\n",
    "\n",
    "$$f^{\\star}(x) = \\underset{y \\in \\{ 0,1 \\}}{argmax} \\space P(Y = y) \\space P(X = x|Y = y) = \n",
    "    \\begin{cases}\n",
    "      1 & \\text{if} \\space \\frac{\\pi_1}{\\sigma_1}\\space exp[- \\frac{(x - \\mu_1)^2}{2 \\sigma^2_1}] > \\frac{\\pi_0}{\\sigma_0}\\space exp[- \\frac{(x - \\mu_0)^2}{2 \\sigma^2_0}]\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Bayes Classifier_\n",
    "![Bayes Classifier](.\\image\\BayesClassifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Bayes Classifier` has the smallest prediction error of all classifiers. The problem is that we need to know the distribution of $P$ in order to construct the `Bayes Classifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES CLASSIFIER\n",
    "\n",
    "A simplifying assumtion that the features values are conditionally independent given the label, the probability of observing the conjunction $x_1, x_2, x_3, ..., x_d$ is the product of the probabilities for the individual features:\n",
    "\n",
    "$$ p(x_1, x_2, x_3, ..., x_d|y) = \\prod \\limits_j \\space p(x_j|y)$$\n",
    "\n",
    "Then the `Naive Bayes Classifier` is defined as:\n",
    "\n",
    "$$f^{\\star}(x) = \\underset{y \\in Y}{argmax} \\space p(y) \\space \\prod \\limits_j \\space p(x_j|y)$$\n",
    "\n",
    "We can estimate these two terms based on the **frequency counts** in the dataset. If the features are real-valued, Naive Bayes can be extended assuming that features follow a Gaussian distribution. This extension is called `Gaussian Naive Bayes`. Other functions can be used to estimate the distribution but the Gaussian distribution is the easiest to work with due to we only need to estimate the mean and the standard deviation from the dataset.\n",
    "\n",
    "Ok, let's start with the implementation of `Gaussian Naive Bayes` from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORTING ALL NECESSARY SUPPORT LIBRARIES\n",
    "import math as mt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_label(dataset):\n",
    "    separate = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        row = dataset[i]\n",
    "        label = row[-1]\n",
    "        if (label not in separate):\n",
    "            separate[label] = list()\n",
    "        separate[label].append(row)\n",
    "        \n",
    "    return separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(list_num):\n",
    "    return sum(list_num)/len(list_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdv(list_num):\n",
    "    mu = mean(list_num)\n",
    "    var = sum([(x - mu)**2 for x in list_num])/(len(list_num) - 1)\n",
    "    \n",
    "    return mt.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_per_feature(ds):\n",
    "    '''\n",
    "    argument:\n",
    "        > ds: 1-D Array with the all data separated by class\n",
    "    returns:\n",
    "        > stats: 1-D Array with statistics summary for each feature\n",
    "    '''\n",
    "    stats = [(mean(col), stdv(col), len(col)) for col in zip(*ds)]\n",
    "    del(stats[-1])\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_by_class(dataset):\n",
    "    sep_label = separate_by_label(dataset)\n",
    "    summary = dict()\n",
    "    for label, rows in sep_label.items():\n",
    "        summary[label] = stats_per_feature(rows)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(mean, stdv, x):\n",
    "    _exp = mt.exp(-1*((x - mean)**2/(2*stdv**2)))\n",
    "    return (1/(mt.sqrt(2 * mt.pi)*stdv)) * _exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to use the statistics calculated from the data to calculate probabilities for new data.\n",
    "\n",
    "Probabilities are calculated separately for each class, so we calculate the probability that a new piece of data belongs to the first class, then calculate the probability that it belongs to the second class, and so on for all the classes.\n",
    "\n",
    "For example, if we have two inputs $x_1 and \\space x_2$ the calculation of the probability that those belong to class = _y_ is:\n",
    "\n",
    "$$P(class = y|x_1,x_2) = P(x_1|class = y) \\cdot P(x_2|class = y) \\cdot P(class = y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_probabilities(summary, row):\n",
    "    total = sum([summary[label][0][2] for label in summary])\n",
    "    probabilities = dict()\n",
    "    \n",
    "    for class_, class_summary in summary.items():\n",
    "        probabilities[class_] = summary[class_][0][2]/total\n",
    "        for i in range(len(class_summary)):\n",
    "            mean, stdev, count = class_summary[i]\n",
    "            probabilities[class_] *= gaussian_pdf(row[i], mean, stdev)\n",
    "            \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summary, row):\n",
    "    cls_prob = class_probabilities(summary, row)\n",
    "    _label, _prob = None, -1.0\n",
    "    for class_, probability in cls_prob.items():\n",
    "        if _label is None or probability > _prob:\n",
    "            _prob = probability\n",
    "            _label = class_\n",
    "            \n",
    "    return _label    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to verify proper implementation a **toy dataset** is used to evaluate the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0, Predicted=0\n",
      "Expected=0, Predicted=0\n",
      "Expected=0, Predicted=0\n",
      "Expected=0, Predicted=0\n",
      "Expected=0, Predicted=0\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n"
     ]
    }
   ],
   "source": [
    "dataset = [[3.393533211,2.331273381,0],\n",
    "[3.110073483,1.781539638,0],\n",
    "[1.343808831,3.368360954,0],\n",
    "[3.582294042,4.67917911,0],\n",
    "[2.280362439,2.866990263,0],\n",
    "[7.423436942,4.696522875,1],\n",
    "[5.745051997,3.533989803,1],\n",
    "[9.172168622,2.511101045,1],\n",
    "[7.792783481,3.424088941,1],\n",
    "[7.939820817,0.791637231,1]]\n",
    "\n",
    "summaries = summary_by_class(dataset)\n",
    "for row in dataset:\n",
    "    y_pred = predict(summaries, row)\n",
    "    y_real = row[-1]\n",
    "    print(\"Expected={0}, Predicted={1}\".format(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _GAUSSIAN NAIVE BAYES APPLICATION_\n",
    "\n",
    "From the `UCI Machine Learning Repository` which contains Iris dataset, we will train our `Gaussian Naive Bayes` model. The Iris dataset is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day.\n",
    "\n",
    "The dataset contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are not linearly separable from each other.\n",
    "\n",
    "The dataset have 150 instances and the following attributes:\n",
    "\n",
    "   1. sepal length in cm\n",
    "   2. sepal width in cm\n",
    "   3. petal length in cm\n",
    "   4. petal width in cm\n",
    "   5. class: \n",
    "      -- Iris Setosa\n",
    "      -- Iris Versicolour\n",
    "      -- Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the performance of our _Classifier_ on the **Iris** dataset, a Gaussian Naive Bayes model from `sklearn` will be fit on the dataset and classification report for both models is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-len</th>\n",
       "      <th>sepal-wid</th>\n",
       "      <th>petal-len</th>\n",
       "      <th>petal-wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-len  sepal-wid  petal-len  petal-wid        class\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##LOADING 'IRIS' DATASET\n",
    "columns = ['sepal-len','sepal-wid','petal-len','petal-wid','class']\n",
    "df = pd.read_csv('./data/Iris.csv', names = columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal-len    150 non-null float64\n",
      "sepal-wid    150 non-null float64\n",
      "petal-len    150 non-null float64\n",
      "petal-wid    150 non-null float64\n",
      "class        150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the class variable type is `categorical` we need first to encode it as numeric type in order to be feed it into our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-len</th>\n",
       "      <th>sepal-wid</th>\n",
       "      <th>petal-len</th>\n",
       "      <th>petal-wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-len  sepal-wid  petal-len  petal-wid  class\n",
       "0        5.1        3.5        1.4        0.2      0\n",
       "1        4.9        3.0        1.4        0.2      0\n",
       "2        4.7        3.2        1.3        0.2      0\n",
       "3        4.6        3.1        1.5        0.2      0\n",
       "4        5.0        3.6        1.4        0.2      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encoder(df, class_value_pair):\n",
    "    for class_name, value in class_value_pair.items():\n",
    "        df['class'] = df['class'].replace(class_name, value)\n",
    "        \n",
    "    return df\n",
    "class_encoder = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n",
    "df = encoder(df, class_encoder)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the preprocessing is complete the dataset will be split into a `Training` & `Test` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = df.drop(['class'],axis = 1)\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size = 0.30, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can `train` our customized model. Noticed that our _Gaussian Naive Bayes_ model expects a complete dataset (attributes and labels) in order to calculate the summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = pd.concat([X_train, y_train], axis = 1)\n",
    "GNB_custom = summary_by_class(ds_train.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = pd.concat([X_test, y_test], axis = 1)\n",
    "cust_pred = [predict(GNB_custom, row) for row in ds_test.values.tolist()]\n",
    "cust_pred = np.array(cust_pred, dtype = 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 2, 0, 2, 2, 1, 0, 0,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now an instance of `sklearn` _Gaussian Naive Bayes_ model is created and fit it with the training data and an array of predictions is obtained in order to get out performance comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GET AND INSTANCE OF GAUSSIAN NAIVE BAYES MODEL\n",
    "GNB_skln = GaussianNB()\n",
    "GNB_skln.fit(X_train, y_train)\n",
    "\n",
    "##CREATE SKLEARN PREDICTIONS ARRAY\n",
    "sk_pred = GNB_skln.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 2, 0, 2, 2, 1, 0, 0,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By last, a comparison on both models is performed thru a _Classification Report_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.88      0.94      0.91        16\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n",
      "Custom:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.88      0.94      0.91        16\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sklearn:\")\n",
    "print(classification_report(y_test, sk_pred))\n",
    "print(\"Custom:\")\n",
    "print(classification_report(y_test, cust_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
